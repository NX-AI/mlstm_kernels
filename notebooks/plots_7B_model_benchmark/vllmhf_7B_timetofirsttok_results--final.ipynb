{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from mlstm_kernels.utils.benchmark.plot_results import (\n",
    "    plot_benchmark_result_table,\n",
    "    rc_context_wrapper,\n",
    "    select_columns,\n",
    ")\n",
    "from pathlib import Path\n",
    "from plot_config import linestyle_mapping, style_dict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collect all results batch size 1\n",
    "# falconmamba_gen_len_1_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_14-24-09__ttft__timetofirsttoken_gencudagraph_falconmamba_v0/hf_7B_timtofirsttok__bs1_gl1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "# falconmamba_gen_len_100_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_14-24-09__ttft__timetofirsttoken_gencudagraph_falconmamba_v0/hf_7B_timtofirsttok__bs1_gl101_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "# codestralmamba_gen_len_1_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_14-35-21__ttft__timetofirsttoken_gencudagraph_codestralmamba_v0/hf_7B_timtofirsttok__bs1_gl1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "# codestralmamba_gen_len_100_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_14-35-21__ttft__timetofirsttoken_gencudagraph_codestralmamba_v0/hf_7B_timtofirsttok__bs1_gl101_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "# mxlstmmamba_gen_len_1_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_15-43-57__ttft__timetofirsttoken_gencudagraph_xmlstm_v0/hf_7B_timtofirsttok__bs1_gl1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "# mxlstmmamba_gen_len_100_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_15-43-57__ttft__timetofirsttoken_gencudagraph_xmlstm_v0/hf_7B_timtofirsttok__bs1_gl101_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "# llama_gen_len_1_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_15-48-51__ttft__timetofirsttoken_gencudagraph_llama_v0/hf_7B_timtofirsttok__bs1_gl1_tcFalse_weightdtypebfloat16/results.csv\"\n",
    "# llama_gen_len_100_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-04_15-48-51__ttft__timetofirsttoken_gencudagraph_llama_v0/hf_7B_timtofirsttok__bs1_gl101_tcFalse_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "# llama_static_gen_len_1_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-05_15-14-03__ttft__llama_static_cache_v0/hf_7B_timtofirsttok__bs1_gl1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "# llama_static_gen_len_100_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-05_15-14-03__ttft__llama_static_cache_v0/hf_7B_timtofirsttok__bs1_gl101_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "# file_dict = {\n",
    "#     \"falconmamba\": (falconmamba_gen_len_1_file, falconmamba_gen_len_100_file),\n",
    "#     \"codestralmamba\": (codestralmamba_gen_len_1_file, codestralmamba_gen_len_100_file),\n",
    "#     \"mxlstmmamba\": (mxlstmmamba_gen_len_1_file, mxlstmmamba_gen_len_100_file),\n",
    "#     \"llama\": (llama_gen_len_1_file, llama_gen_len_100_file),\n",
    "#     \"llama_static\": (llama_static_gen_len_1_file, llama_static_gen_len_100_file),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timetofirst_token_results(gen_len_1_file, gen_len_100_file):\n",
    "    gen_len_1_df = pd.read_csv(gen_len_1_file).filter(regex=\".*(prefill|R--.*).*\")\n",
    "    gen_len_100_df = pd.read_csv(gen_len_100_file).filter(regex=\".*(prefill|R--.*).*\")\n",
    "    tok_per_sec_data_df = 100 / (\n",
    "        (gen_len_100_df.filter(regex=\".*R--.*\") - gen_len_1_df.filter(regex=\".*R--.*\"))\n",
    "        / 1000\n",
    "    )\n",
    "    tok_per_sec_df = pd.concat(\n",
    "        [gen_len_1_df.filter(regex=\".*prefill.*\"), tok_per_sec_data_df], axis=1\n",
    "    )\n",
    "    tok_per_sec_df, gen_len_1_df, gen_len_100_df = [\n",
    "        df.rename(columns={col:col+\"_vllm\" for col in df.columns[1:]})\n",
    "        for df in [tok_per_sec_df, gen_len_1_df, gen_len_100_df]\n",
    "    ]\n",
    "    return tok_per_sec_df, gen_len_1_df, gen_len_100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict = load_timetofirst_token_results(\n",
    "    \"../../outputs_kernel_benchmarks/2025-03-26_15-19-07__ttft__testvllm/hf_7B_timtofirsttok__bs1_gl1_tcFalse_weightdtypebfloat16/results.csv\",\n",
    "    \"../../outputs_kernel_benchmarks/2025-03-26_15-19-07__ttft__testvllm/hf_7B_timtofirsttok__bs1_gl101_tcFalse_weightdtypebfloat16/results.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_per_sec_df = pd.concat([v[0] for v in dataframe_dict.values()], axis=1)\n",
    "# token_per_sec_df = pd.concat(\n",
    "#     [\n",
    "#         token_per_sec_df.filter(regex=\".*prefill.*\").take([0], axis=1),\n",
    "#         token_per_sec_df.filter(regex=\".*R--.*\"),\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# token_per_sec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttft_1_df = pd.concat([v[1] for v in dataframe_dict.values()], axis=1)\n",
    "# ttft_1_df = pd.concat(\n",
    "#     [\n",
    "#         ttft_1_df.filter(regex=\".*prefill.*\").take([0], axis=1),\n",
    "#         ttft_1_df.filter(regex=\".*R--.*\"),\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# ttft_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttft_100_df = pd.concat([v[2] for v in dataframe_dict.values()], axis=1)\n",
    "# ttft_100_df = pd.concat(\n",
    "#     [\n",
    "#         ttft_100_df.filter(regex=\".*prefill.*\").take([0], axis=1),\n",
    "#         ttft_100_df.filter(regex=\".*R--.*\"),\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# ttft_100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = {\n",
    "#     \"token_per_sec\": token_per_sec_df,\n",
    "#     \"ttft_1\": ttft_1_df,\n",
    "#     \"ttft_100\": ttft_100_df,\n",
    "# }\n",
    "# with open(\"ttft_raw_data.p\", \"wb\") as f:\n",
    "#     pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in raw_data.items():\n",
    "#     v.to_csv(f\"raw_data_ttft_{k}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ttft_raw_data.p\", \"rb\") as f:\n",
    "    raw_data = pickle.load(f)\n",
    "\n",
    "ttft_1_df = raw_data[\"ttft_1\"]\n",
    "ttft_100_df = raw_data[\"ttft_100\"]\n",
    "token_per_sec_df = raw_data[\"token_per_sec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttft_1_df = pd.concat([ttft_1_df, dataframe_dict[1].filter(regex=\"R.*\")], axis=1)\n",
    "ttft_100_df = pd.concat([ttft_100_df, dataframe_dict[2].filter(regex=\"R.*\")], axis=1)\n",
    "token_per_sec_df = pd.concat([token_per_sec_df, dataframe_dict[0].filter(regex=\"R.*\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_per_sec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttft_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    \"token_per_sec\": token_per_sec_df,\n",
    "    \"ttft_1\": ttft_1_df,\n",
    "    \"ttft_100\": ttft_100_df,\n",
    "}\n",
    "with open(\"ttft_raw_data_vllm.p\", \"wb\") as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_benchmark_result_table(\n",
    "    ttft_1_df,\n",
    "    x_axis_param=\"prefill_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    # style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Time [ms]\",\n",
    "    title=\"Time to generate 1 tokens, for varying prefill lengths\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_benchmark_result_table(\n",
    "    ttft_100_df,\n",
    "    x_axis_param=\"prefill_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    # style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Time [ms]\",\n",
    "    title=\"Time to generate 100 tokens, for varying prefill lengths\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_benchmark_result_table(\n",
    "    token_per_sec_df,\n",
    "    x_axis_param=\"prefill_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    # style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Tokens per second\",\n",
    "    title=\"Tokens per second during generation of 100 tokens after consuming varying prefill lengths (bs1 gl100)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plots - All results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"llama3\": \"R--llama3__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "    \"llama2\": \"R--llama2__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "    \"falcon_mamba\": \"R--falcon_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "    \"codestral_mamba\": \"R--codestral_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "    \"xlstm\": \"R--xlstm__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False_isd-bfloat16_ed-4096_nh-8_nb-32_vs-50304_wm-fused_ck-chunkwise--triton_xl_chunk_sk-native_sequence__triton_step_fused_sk-triton_fused_cs-128_akd-bfloat16\",\n",
    "}\n",
    "filename_suffix = \"\"\n",
    "add_legend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttft_1_plot_df = select_columns(\n",
    "    ttft_1_df, selected_columns, keep_col_regex=\".*prefill.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rc_context_wrapper(\n",
    "    func=plot_benchmark_result_table,\n",
    "    result_df=ttft_1_plot_df,\n",
    "    x_axis_param=\"prefill_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Time to First Token [ms]\",\n",
    "    x_label=\"Prefill Length\",\n",
    "    title=\"\",  # \"Time to generate 1 tokens, for varying prefill lengths\",\n",
    "    figsize=(1.2 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "    filename=f\"timetofirsttoken_1_tokens{filename_suffix}\",\n",
    "    add_legend=add_legend,\n",
    "    legend_args={\n",
    "        \"loc\": \"lower center\",\n",
    "        \"ncol\": 3,\n",
    "        \"bbox_to_anchor\": (0.0, 1.02, 1.0, 0.502),\n",
    "        \"frameon\": False,\n",
    "        \"facecolor\": \"white\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttft_100_plot_df = select_columns(\n",
    "    ttft_100_df, selected_columns, keep_col_regex=\".*prefill.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rc_context_wrapper(\n",
    "    func=plot_benchmark_result_table,\n",
    "    result_df=ttft_100_plot_df,\n",
    "    x_axis_param=\"prefill_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Time to First 100 Token [ms]\",\n",
    "    x_label=\"Prefill Length\",\n",
    "    title=\"\",  # \"Time to generate 100 tokens, for varying prefill lengths\",\n",
    "    figsize=(1.2 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "    filename=f\"timetofirsttoken_100_tokens_prefill_length{filename_suffix}\",\n",
    "    add_legend=False,  # add_legend,\n",
    "    legend_args={\n",
    "        \"loc\": \"lower center\",\n",
    "        \"ncol\": 3,\n",
    "        \"bbox_to_anchor\": (0.0, 1.02, 1.0, 0.502),\n",
    "        \"frameon\": False,\n",
    "        \"facecolor\": \"white\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_per_sec_plot_df = select_columns(\n",
    "    token_per_sec_df, selected_columns, keep_col_regex=\".*prefill.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rc_context_wrapper(\n",
    "    func=plot_benchmark_result_table,\n",
    "    result_df=token_per_sec_plot_df,\n",
    "    x_axis_param=\"prefill_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Tokens per Second\",\n",
    "    title=\"\",  # \"Tokens per second during generation of 100 tokens after consuming varying prefill lengths (bs1 gl100)\",\n",
    "    x_label=\"Prefill Length\",\n",
    "    figsize=(1.6 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "    filename=f\"timetofirsttoken_tokens_per_sec{filename_suffix}\",\n",
    "    add_legend=add_legend,\n",
    "    legend_args={\n",
    "        \"loc\": \"lower center\",\n",
    "        \"ncol\": 3,\n",
    "        \"bbox_to_anchor\": (0.0, 1.02, 1.0, 0.502),\n",
    "        \"frameon\": False,\n",
    "        \"facecolor\": \"white\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_columns = {\n",
    "#     \"llama3\": \"R--llama3__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "#     # \"llama2\": \"R--llama2__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "#     # \"falcon_mamba\": \"R--falcon_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "#     \"codestral_mamba\": \"R--codestral_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False\",\n",
    "#     \"xlstm\": \"R--xlstm__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-True_ucgm-False_isd-bfloat16_ed-4096_nh-8_nb-32_vs-50304_wm-fused_ck-chunkwise--triton_xl_chunk_sk-native_sequence__triton_step_fused_sk-triton_fused_cs-128_akd-bfloat16\",\n",
    "# }\n",
    "# filename_suffix = \"only_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttft_1_plot_df = select_columns(\n",
    "#     ttft_1_df, selected_columns, keep_col_regex=\".*prefill.*\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = rc_context_wrapper(\n",
    "#     func=plot_benchmark_result_table,\n",
    "#     result_df=ttft_1_plot_df,\n",
    "#     x_axis_param=\"prefill_length\",\n",
    "#     # linestyle_mapping=linestyle_mapping,\n",
    "#     style_dict=style_dict,\n",
    "#     style_dict_colname_mapping_exact=False,\n",
    "#     y_label=\"Time to First Token [ms]\",\n",
    "#     x_label=\"Prefill Length\",\n",
    "#     title=\"\",  # \"Time to generate 1 tokens, for varying prefill lengths\",\n",
    "#     figsize=(1.5 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "#     filename=f\"timetofirsttoken_1_tokens{filename_suffix}\",\n",
    "#     add_legend=add_legend,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttft_100_plot_df = select_columns(\n",
    "#     ttft_100_df, selected_columns, keep_col_regex=\".*prefill.*\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = rc_context_wrapper(\n",
    "#     func=plot_benchmark_result_table,\n",
    "#     result_df=ttft_100_plot_df,\n",
    "#     x_axis_param=\"prefill_length\",\n",
    "#     # linestyle_mapping=linestyle_mapping,\n",
    "#     style_dict=style_dict,\n",
    "#     style_dict_colname_mapping_exact=False,\n",
    "#     y_label=\"Time to First 100 Token [ms]\",\n",
    "#     x_label=\"Prefill Length\",\n",
    "#     title=\"\",  # \"Time to generate 100 tokens, for varying prefill lengths\",\n",
    "#     figsize=(1.5 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "#     filename=f\"timetofirsttoken_100_tokens_prefill_length{filename_suffix}\",\n",
    "#     add_legend=add_legend,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_per_sec_plot_df = select_columns(\n",
    "#     token_per_sec_df, selected_columns, keep_col_regex=\".*prefill.*\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = rc_context_wrapper(\n",
    "#     func=plot_benchmark_result_table,\n",
    "#     result_df=token_per_sec_plot_df,\n",
    "#     x_axis_param=\"prefill_length\",\n",
    "#     # linestyle_mapping=linestyle_mapping,\n",
    "#     style_dict=style_dict,\n",
    "#     style_dict_colname_mapping_exact=False,\n",
    "#     y_label=\"Tokens per Second\",\n",
    "#     title=\"\",  # \"Tokens per second during generation of 100 tokens after consuming varying prefill lengths (bs1 gl100)\",\n",
    "#     x_label=\"Prefill Length\",\n",
    "#     figsize=(1.5 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "#     filename=f\"timetofirsttoken_tokens_per_sec{filename_suffix}\",\n",
    "#     add_legend=add_legend,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt260cu126_speedvllm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
